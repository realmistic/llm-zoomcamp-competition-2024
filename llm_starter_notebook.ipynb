{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/realmistic/Documents/llm-zoomcamp-competition-2024\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Test Local LLM (downloaded with Ollama, use OpenAI lib for calling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                    \tID          \tSIZE  \tMODIFIED    \n",
      "mixtral:8x22b           \te8479ee1cb51\t79 GB \t10 days ago\t\n",
      "phi3:14b                \tcf611a26b048\t7.9 GB\t10 days ago\t\n",
      "deepseek-coder-v2:latest\t8577f96d693e\t8.9 GB\t10 days ago\t\n",
      "qwen2:72b               \t14066dfa503f\t41 GB \t10 days ago\t\n",
      "mistral-large:latest    \t0ca7dfa0bf06\t69 GB \t10 days ago\t\n",
      "gemma2:27b              \t53261bc9c192\t15 GB \t10 days ago\t\n",
      "llama3:70b              \t786f3184aec0\t39 GB \t10 days ago\t\n",
      "llama3.1:latest         \t91ab477bec9d\t4.7 GB\t11 days ago\t\n"
     ]
    }
   ],
   "source": [
    "# list of available local models\n",
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama - OpenAI Compatibility: https://ollama.com/blog/openai-compatibility\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small model by default for fast computation\n",
    "def llm(prompt, model = 'llama3.1:latest'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature= 0.0,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'tell me a joke'\n",
    "\n",
    "r = llm(prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's one:\\n\\nWhat do you call a fake noodle?\\n\\nAn impasta.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Wrapper for solving math problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question, model = 'llama3.1:latest'):\n",
    "    prompt = f\"\"\"Role:\n",
    "    You are an advanced AI system with exceptional mathematical reasoning and problem-solving capabilities, specifically designed to solve tricky math problems (whose answer is a non-negative integer) written in LaTeX format from the AI Mathematical Olympiad (AIMO) competition. Your task is to accurately analyze and solve intricate mathematical problems, demonstrating a deep understanding of mathematical concepts and a strong ability to apply logical reasoning strategies.\n",
    "\n",
    "    Instruction:\n",
    "    1. Carefully read and comprehend the problem statement provided in the \"Problem\" section.\n",
    "    2. In the \"Solution\" section, provide a solution of the problem with detailed explanation of your logical reasoning process. Keep in mind that answer must be a non-negative integer number.\n",
    "    3. At the end, create a \"Answer\" section where you will state only the final numerical (convert fractions to approx. numbers, try not to do rounding) or algebraic answer, without any additional text or narrative.\n",
    "\n",
    "    Problem:\n",
    "    ...\n",
    "\n",
    "    Solution:\n",
    "    ...\n",
    "\n",
    "    Answer:\n",
    "    ...\n",
    "\n",
    "    {question}\n",
    "\n",
    "    Step-by-step solution and final answer:\"\"\"\n",
    "\n",
    "    response = llm(prompt=prompt, model=model)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract numerical\n",
    "import re\n",
    "\n",
    "def extract_numerical_answer(text):\n",
    "    # Look for patterns like \"Final answer: X\" or \"The answer is X\" at the end of the text\n",
    "    match = re.search(r'(?:final answer|the answer is)[:\\s]*([+-]?\\d*\\.?\\d+)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    else:\n",
    "        # If no clear final answer, look for the last number in the text\n",
    "        numbers = re.findall(r'[+-]?\\d*\\.?\\d+', text)\n",
    "        if numbers:\n",
    "            number = float(numbers[-1])\n",
    "            # Check if the number is an integer\n",
    "            if number.is_integer():\n",
    "                return int(number)\n",
    "            else:\n",
    "                return number\n",
    "        return None\n",
    "        \n",
    "        # old: returned only float\n",
    "        # return float(numbers[-1]) if numbers else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check input and output\n",
    "def show_latex_text(latex_text:str):\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(6, 8), dpi=100)  # Adjust figure size and DPI\n",
    "\n",
    "    # Hide axes\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Add the text with padding\n",
    "    plt.text(0.5, \n",
    "             0.5, \n",
    "             latex_text, \n",
    "             horizontalalignment='center', \n",
    "             verticalalignment='center', \n",
    "             fontsize=10, \n",
    "             wrap=True)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout(pad=2.0)  # Add padding\n",
    "\n",
    "    # Save the figure to a BytesIO object\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png', bbox_inches='tight')\n",
    "    buf.seek(0)\n",
    "\n",
    "    # Convert to base64\n",
    "    img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
    "\n",
    "    # Display the image in the notebook\n",
    "    html = f'<img src=\"data:image/png;base64,{img_base64}\" style=\"max-width:100%; height:auto;\" />'\n",
    "    display(HTML(html))\n",
    "\n",
    "    # Clean up\n",
    "    plt.close(fig)\n",
    "    \n",
    "    #     # Create a figure and axis with adjusted size\n",
    "    # fig, ax = plt.subplots(figsize=(8, 2), dpi=100)  # Adjust figure size as needed\n",
    "\n",
    "    # # Hide axes\n",
    "    # ax.axis('off')\n",
    "\n",
    "    # # Add LaTeX text with centering\n",
    "    # ax.text(0.5, 0.5, f\"${latex_text}$\", horizontalalignment='center', verticalalignment='center', fontsize=14, usetex=True)\n",
    "\n",
    "    # # Adjust layout to minimize white space\n",
    "    # plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\n",
    "\n",
    "    # # Save the figure to a BytesIO object\n",
    "    # buf = io.BytesIO()\n",
    "    # fig.savefig(buf, format='png', bbox_inches='tight', pad_inches=0.1)\n",
    "    # buf.seek(0)\n",
    "\n",
    "    # # Convert to base64\n",
    "    # img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
    "\n",
    "    # # Display the image in the notebook\n",
    "    # html = f'<img src=\"data:image/png;base64,{img_base64}\" style=\"max-width:100%; height:auto;\" />'\n",
    "    # display(HTML(html))\n",
    "\n",
    "    # # Clean up\n",
    "    # plt.close(fig)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from IPython.display import Image\n",
    "import io\n",
    "\n",
    "# Configure Matplotlib to use LaTeX\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "def show_latex_as_image(latex_string):\n",
    "    # Create a figure and an axis\n",
    "    fig, ax = plt.subplots(figsize=(4, 1), dpi=200)\n",
    "    \n",
    "    # Hide the axes\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Display the LaTeX string\n",
    "    plt.text(0.5, 0.5, f\"${latex_string}$\", \n",
    "             horizontalalignment='center', \n",
    "             verticalalignment='center', \n",
    "             fontsize=12)\n",
    "    \n",
    "    # Adjust layout\n",
    "    # plt.tight_layout(pad=1.0)\n",
    "    \n",
    "    # Save the figure to a BytesIO object\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0.1)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # Close the plot to free memory\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Display the image\n",
    "    display(Image(data=buf.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem_id</th>\n",
       "      <th>problem_text</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2374</td>\n",
       "      <td>Find the value of the expression $\\dfrac{17}{5...</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4723</td>\n",
       "      <td>In a company of 30 people, 25 use the social n...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7135</td>\n",
       "      <td>The number of road traffic accidents (RTAs) in...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5814</td>\n",
       "      <td>Find the value of the expression $\\dfrac{2\\str...</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237</td>\n",
       "      <td>A traveler from Moscow wants to visit four cit...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   problem_id                                       problem_text answer\n",
       "0        2374  Find the value of the expression $\\dfrac{17}{5...    1.6\n",
       "1        4723  In a company of 30 people, 25 use the social n...     24\n",
       "2        7135  The number of road traffic accidents (RTAs) in...     32\n",
       "3        5814  Find the value of the expression $\\dfrac{2\\str...    256\n",
       "4        9237  A traveler from Moscow wants to visit four cit...     53"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloaded data from kaggle https://www.kaggle.com/competitions/llm-zoomcamp-2024-competition/data\n",
    "df_train = pd.read_csv('input_data/train.csv')\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = df_train.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem_id': 5814,\n",
       " 'problem_text': 'Find the value of the expression $\\\\dfrac{2\\\\strut^{-5} \\\\cdot 2\\\\strut^{9} }{2\\\\strut^{-4} } $.',\n",
       " 'answer': '256'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one row\n",
    "rows[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                    \tID          \tSIZE  \tMODIFIED    \n",
      "mixtral:8x22b           \te8479ee1cb51\t79 GB \t10 days ago\t\n",
      "phi3:14b                \tcf611a26b048\t7.9 GB\t10 days ago\t\n",
      "deepseek-coder-v2:latest\t8577f96d693e\t8.9 GB\t10 days ago\t\n",
      "qwen2:72b               \t14066dfa503f\t41 GB \t10 days ago\t\n",
      "mistral-large:latest    \t0ca7dfa0bf06\t69 GB \t10 days ago\t\n",
      "gemma2:27b              \t53261bc9c192\t15 GB \t10 days ago\t\n",
      "llama3:70b              \t786f3184aec0\t39 GB \t10 days ago\t\n",
      "llama3.1:latest         \t91ab477bec9d\t4.7 GB\t11 days ago\t\n"
     ]
    }
   ],
   "source": [
    "# check downloaded models from the library: https://ollama.com/library\n",
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_one_problem(one_row, model = \"phi3:14b\", verbose = False):\n",
    "    if verbose: #show rendered problem\n",
    "        show_latex_text(one_row['problem_text'])\n",
    "        # show_latex_as_image(one_row['problem_text'])\n",
    "        \n",
    "    llm_response = get_answer(question=one_row['problem_text'], model = model)\n",
    "    ans = llm_response.choices[0].message.content\n",
    "    ans2 = ans.replace('\\\\strut', '').replace('$$', '$') \n",
    "    res = extract_numerical_answer(ans)\n",
    "\n",
    "    # DEBUG: answer by LLM + right/wrong\n",
    "    \n",
    "    # SHOW INPUTS:\n",
    "    # for k in one_row.keys():\n",
    "    #     print(f'[{k}]: {one_row[k]}')\n",
    "\n",
    "    # print(f'answer by llm {model}: {res}')\n",
    "    \n",
    "    if verbose:  #show  logics\n",
    "        show_latex_text(ans2)\n",
    "        # show_latex_as_image(ans2)\n",
    "\n",
    "\n",
    "    return res, llm_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# if not installed Latex (shows not everything correctly:)\n",
    "# mpl.rcParams['text.usetex'] = False\n",
    "\n",
    "# Ensure LaTeX support in Matplotlib\n",
    "# installed previously Latex on Mac in terminal: brew install --cask mactex\n",
    "\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "# mpl.rcParams['text.latex.preamble'] = [r'\\usepackage{amsmath}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                    \tID          \tSIZE  \tMODIFIED    \n",
      "mixtral:8x22b           \te8479ee1cb51\t79 GB \t10 days ago\t\n",
      "phi3:14b                \tcf611a26b048\t7.9 GB\t10 days ago\t\n",
      "deepseek-coder-v2:latest\t8577f96d693e\t8.9 GB\t10 days ago\t\n",
      "qwen2:72b               \t14066dfa503f\t41 GB \t10 days ago\t\n",
      "mistral-large:latest    \t0ca7dfa0bf06\t69 GB \t10 days ago\t\n",
      "gemma2:27b              \t53261bc9c192\t15 GB \t10 days ago\t\n",
      "llama3:70b              \t786f3184aec0\t39 GB \t10 days ago\t\n",
      "llama3.1:latest         \t91ab477bec9d\t4.7 GB\t11 days ago\t\n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phi3:14b\n",
    "# gemma2:27b\n",
    "# qwen2:72b\n",
    "\n",
    "# +(2m24) mixtral:8x22b :: CORRECT          \n",
    "# +(1m37) qwen2:72b     :: CORRECT        \t\n",
    "# +(4m21) mistral-large:latest ::\talmost Correct\n",
    "# +(23s) phi3:14b ::\talmost Correct\n",
    "\n",
    "res, msg = solve_one_problem(rows[4], model = 'llama3.1:latest', verbose=False)\n",
    "# print(res, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/realmistic/Documents/llm-zoomcamp-competition-2024/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "pool = ThreadPoolExecutor(max_workers=14)\n",
    "\n",
    "def map_progress(pool, seq, f):\n",
    "    results = []\n",
    "\n",
    "    with tqdm(total=len(seq)) as progress:\n",
    "        futures = []\n",
    "\n",
    "        for el in seq:\n",
    "            future = pool.submit(f, el)\n",
    "            future.add_done_callback(lambda p: progress.update())\n",
    "            futures.append(future)\n",
    "\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row, model = 'llama3.1:latest'):\n",
    "    problem_id = row['problem_id']\n",
    "    problem_text = row['problem_text']\n",
    "    problem_answer = None\n",
    "    if 'answer' in row.keys():\n",
    "        problem_answer = row['answer']\n",
    "    # llm_reasoning = get_answer(problem_text)\n",
    "    # numerical_answer = extract_numerical_answer(llm_reasoning)\n",
    "    numerical_answer, llm_reasoning = solve_one_problem(row, model = model, verbose=False)\n",
    "    \n",
    "    correct = None\n",
    "    if problem_answer is not None:\n",
    "        if problem_answer == str(numerical_answer):\n",
    "            correct = True\n",
    "            print('CORRECT ANSWER')\n",
    "        else:\n",
    "            correct = False\n",
    "            print('WRONG ANSWER')\n",
    "            print(f' Let\\'s compare answers: LLM_ANSWER: {numerical_answer}, TRUE_ANSWER: {problem_answer}')\n",
    "\n",
    "    return {\n",
    "        'problem_id': problem_id,\n",
    "        'problem_text': problem_text,\n",
    "        'problem_answer':problem_answer,\n",
    "        'llm_reasoning': llm_reasoning,\n",
    "        'llm_answer': str(numerical_answer),\n",
    "        'is_correct': correct\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 85, TRUE_ANSWER: 1.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'problem_id': 2374,\n",
       " 'problem_text': 'Find the value of the expression $\\\\dfrac{17}{5} :\\\\dfrac{34}{3} +1.3$.',\n",
       " 'problem_answer': '1.6',\n",
       " 'llm_reasoning': \"Problem:\\n\\n\\nSolution:\\n\\n\\nTo solve this problem, we first need to understand that the colon (:) is not a standard mathematical operator, but rather an indication of division. Therefore, we can rewrite the expression as follows:\\n\\n$\\\\dfrac{17}{5} \\\\div \\\\dfrac{34}{3} + 1.3$\\n\\nNow, let's simplify this expression step by step.\\n\\nFirst, we perform the division operation:\\n\\n$\\\\dfrac{17}{5} \\\\div \\\\dfrac{34}{3} = \\\\dfrac{17}{5} \\\\times \\\\dfrac{3}{34}$\\n\\nNext, we multiply the numerators and denominators:\\n\\n$\\\\dfrac{17 \\\\times 3}{5 \\\\times 34} = \\\\dfrac{51}{170}$\\n\\nNow, let's add 1.3 to this result:\\n\\n$\\\\dfrac{51}{170} + 1.3$\\n\\nTo add a fraction and a decimal, we need to convert the decimal to a fraction with the same denominator as the fraction. We can rewrite 1.3 as $\\\\dfrac{13}{10}$.\\n\\nNow, let's find a common denominator for $\\\\dfrac{51}{170}$ and $\\\\dfrac{13}{10}$. The least common multiple of 170 and 10 is 1700.\\n\\nWe can now convert both fractions to have the same denominator:\\n\\n$\\\\dfrac{51}{170} = \\\\dfrac{51 \\\\times 10}{170 \\\\times 10} = \\\\dfrac{510}{1700}$\\n\\nand\\n\\n$\\\\dfrac{13}{10} = \\\\dfrac{13 \\\\times 170}{10 \\\\times 170} = \\\\dfrac{2210}{1700}$\\n\\nNow, let's add these two fractions:\\n\\n$\\\\dfrac{510}{1700} + \\\\dfrac{2210}{1700} = \\\\dfrac{510 + 2210}{1700} = \\\\dfrac{2720}{1700}$\\n\\nWe can simplify this fraction by dividing both the numerator and denominator by their greatest common divisor, which is 20:\\n\\n$\\\\dfrac{2720}{1700} = \\\\dfrac{136}{85}$\\n\\n\\nAnswer:\\n\\n\\n$\\\\boxed{\\\\dfrac{136}{85}}$\",\n",
       " 'llm_answer': '85',\n",
       " 'is_correct': False}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check process one row\n",
    "process_row(rows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                            | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██▌                                                                                                                                                                                                                                                                 | 1/100 [00:17<29:13, 17.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 16, TRUE_ANSWER: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█████▏                                                                                                                                                                                                                                                              | 2/100 [00:18<12:41,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 124, TRUE_ANSWER: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███████▊                                                                                                                                                                                                                                                            | 3/100 [00:24<11:35,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 85, TRUE_ANSWER: 1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████████▍                                                                                                                                                                                                                                                         | 4/100 [00:34<13:09,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT ANSWER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████████████                                                                                                                                                                                                                                                       | 5/100 [00:36<09:30,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 1060, TRUE_ANSWER: 27000; 64000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|███████████████▌                                                                                                                                                                                                                                                    | 6/100 [00:47<11:58,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 425, TRUE_ANSWER: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████████████████▏                                                                                                                                                                                                                                                 | 7/100 [00:48<08:27,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT ANSWER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████████████████▊                                                                                                                                                                                                                                               | 8/100 [01:02<12:40,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT ANSWER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████████████████████▍                                                                                                                                                                                                                                            | 9/100 [01:08<11:22,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 5, TRUE_ANSWER: 1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████████████████████▉                                                                                                                                                                                                                                         | 10/100 [01:10<08:36,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 10, TRUE_ANSWER: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████████████████████████▍                                                                                                                                                                                                                                      | 11/100 [01:22<11:22,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT ANSWER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████████████████████████                                                                                                                                                                                                                                    | 12/100 [01:25<09:15,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT ANSWER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████████████████████████████████▋                                                                                                                                                                                                                                 | 13/100 [01:40<12:50,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT ANSWER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████████████████████████▎                                                                                                                                                                                                                              | 14/100 [01:43<10:00,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT ANSWER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████████████████████████████▊                                                                                                                                                                                                                            | 15/100 [01:54<11:47,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT ANSWER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████████████████████████████████▍                                                                                                                                                                                                                         | 16/100 [02:30<23:27, 16.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT ANSWER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████████████████████████████████                                                                                                                                                                                                                       | 17/100 [02:44<21:41, 15.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 1, TRUE_ANSWER: 3412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████████████████████████████████████▌                                                                                                                                                                                                                    | 18/100 [03:05<23:34, 17.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 153, TRUE_ANSWER: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████████████████████████████████▏                                                                                                                                                                                                                 | 19/100 [03:09<18:04, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 4, TRUE_ANSWER: -4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████████████████████████████████▊                                                                                                                                                                                                               | 20/100 [03:19<16:34, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT ANSWER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████████████████████████████████████████▍                                                                                                                                                                                                            | 21/100 [03:24<13:30, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 3, TRUE_ANSWER: 4213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████████████████████████████████████████████▉                                                                                                                                                                                                          | 22/100 [04:12<27:48, 21.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 12356, TRUE_ANSWER: 135, 346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████████████████████████████████████████████▌                                                                                                                                                                                                       | 23/100 [04:41<30:28, 23.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 4, TRUE_ANSWER: 1432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████████████████████████████████████████████████▏                                                                                                                                                                                                    | 24/100 [04:48<23:38, 18.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT ANSWER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████████████████████████████████████████████████▊                                                                                                                                                                                                  | 25/100 [05:21<28:47, 23.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT ANSWER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████████████████████████████████████████████████▊                                                                                                                                                                                                  | 25/100 [10:13<30:41, 24.55s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmap_progress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_row\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[1;32m      3\u001b[0m df_results\n",
      "Cell \u001b[0;32mIn[21], line 19\u001b[0m, in \u001b[0;36mmap_progress\u001b[0;34m(pool, seq, f)\u001b[0m\n\u001b[1;32m     16\u001b[0m         futures\u001b[38;5;241m.\u001b[39mappend(future)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m futures:\n\u001b[0;32m---> 19\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 234, TRUE_ANSWER: 23\n",
      "CORRECT ANSWER\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 2, TRUE_ANSWER: -2.5\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 250, TRUE_ANSWER: 25\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 27, TRUE_ANSWER: 6\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 10, TRUE_ANSWER: 0.9\n",
      "CORRECT ANSWER\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 12.5, TRUE_ANSWER: 2.6\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 5, TRUE_ANSWER: 235\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 2, TRUE_ANSWER: 3412\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 3, TRUE_ANSWER: 17490\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 1650, TRUE_ANSWER: 2.18\n",
      "CORRECT ANSWER\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 19, TRUE_ANSWER: 12\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 515, TRUE_ANSWER: 12505\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 23, TRUE_ANSWER: 22.4\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 3, TRUE_ANSWER: 2413\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 8, TRUE_ANSWER: 0.125\n",
      "CORRECT ANSWER\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 25, TRUE_ANSWER: 0.84\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 51, TRUE_ANSWER: 72\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 1091, TRUE_ANSWER: 1\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 775, TRUE_ANSWER: 738\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 3456, TRUE_ANSWER: 34\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 25, TRUE_ANSWER: 2.44\n",
      "CORRECT ANSWER\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 4, TRUE_ANSWER: 24\n",
      "CORRECT ANSWER\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 162, TRUE_ANSWER: 2250\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 4, TRUE_ANSWER: 0.75\n",
      "CORRECT ANSWER\n",
      "CORRECT ANSWER\n",
      "WRONG ANSWER\n",
      " Let's compare answers: LLM_ANSWER: 2, TRUE_ANSWER: 8.5\n"
     ]
    }
   ],
   "source": [
    "results = map_progress(pool, rows, process_row)\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['is_correct_num']= df_results.is_correct.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score ratio\n",
    "sum(df_results['is_correct_num'])/len(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Test submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('input_data/test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
